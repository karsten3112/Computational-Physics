{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, \"../../\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from classes.nn_classes import train_model, NNmodel\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterDataset(Dataset):\n",
    "    def __init__(self, data_from_file, label_index=1) -> None:\n",
    "        super().__init__()\n",
    "        self.data = torch.tensor(np.array([data[0] for data in data_from_file]),dtype=torch.float32)\n",
    "        self.labels = torch.tensor(np.array([data[label_index] for data in data_from_file]),dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flat = np.loadtxt('../pos_e1_e2_e3_1000.txt')\n",
    "data_in_file = [[d[:24].reshape(12,2),d[24],d[25],d[26]] for d in data_flat]\n",
    "\n",
    "ENERGY_LABEL = 1\n",
    "\n",
    "dataset_train = ClusterDataset(data_in_file[0:799], label_index=ENERGY_LABEL)\n",
    "dataset_val = ClusterDataset(data_in_file[799:899], label_index=ENERGY_LABEL)\n",
    "dataset_test = ClusterDataset(data_in_file[899:999], label_index=ENERGY_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LJGNN(torch.nn.Module):\n",
    "    def __init__(self, eps=0.5, sigma_squared=0.03, r0=1.6, eInf=0.1, A=0.9) -> None:\n",
    "        super().__init__()\n",
    "        self.A = torch.nn.Parameter(torch.tensor(float(A)))\n",
    "        self.eps = torch.nn.Parameter(torch.tensor(float(eps)))\n",
    "        self.r0 = torch.nn.Parameter(torch.tensor(float(r0)))\n",
    "        self.sigma_squared = torch.nn.Parameter(torch.tensor(float(sigma_squared)))\n",
    "        self.epsinf = torch.nn.Parameter(torch.tensor(float(eInf)))\n",
    "    \n",
    "    def _V(self, r):\n",
    "        t1 = self.eps*torch.exp(-(r - self.r0)**2/(2.0*self.sigma_squared))\n",
    "        t2 = (1.0/r)**12 - 2.0*(1.0/r)**6\n",
    "        return self.A*(t2-t1) + self.epsinf\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        pairwise_distances = torch.stack([torch.pdist(coords[i]) for i in range(coords.size(0))])\n",
    "        return torch.sum(self._V(pairwise_distances), dim=1)\n",
    "\n",
    "class Pot_NN(torch.nn.Module):\n",
    "    def __init__(self, num_hidden_layers=4, dim_hiddens=15, activation_func=torch.nn.Softplus(), bias=True) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_layers = torch.nn.ParameterList()\n",
    "        self.input_layer = torch.nn.Linear(1, dim_hiddens, bias=bias, dtype=torch.float)\n",
    "        self.output_layer = torch.nn.Linear(dim_hiddens, 1, bias=bias, dtype=torch.float)\n",
    "        self.activation_func = activation_func\n",
    "        for num in range(num_hidden_layers):\n",
    "            self.hidden_layers.append(torch.nn.Linear(dim_hiddens, dim_hiddens, bias=bias, dtype=torch.float))\n",
    "\n",
    "    def _V(self, r):\n",
    "        pot = self.activation_func(self.input_layer(r))\n",
    "        for layer in self.hidden_layers:\n",
    "            pot = self.activation_func(layer(pot))\n",
    "        return self.output_layer(pot)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        pairwise_distances = torch.stack([torch.pdist(coords[i]) for i in range(coords.size(0))])\n",
    "        return torch.sum(self._V(pairwise_distances), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=dataset_train, batch_size=10, shuffle=True)\n",
    "val_loader = DataLoader(dataset=dataset_val, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(dataset=dataset_test, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "patience=100\n",
    "LJGmodel = LJGNN()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=LJGmodel.parameters(), lr=1e-3)\n",
    "train_losses, val_losses, test_loss = train_model(epochs=epochs, model=LJGmodel, \n",
    "                                       train_loader=train_loader, \n",
    "                                       val_loader=val_loader, \n",
    "                                       optimizer=optimizer, \n",
    "                                       test_loader=test_loader, \n",
    "                                       early_stopping=True,\n",
    "                                       patience=patience\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,4, figsize=(14,3), layout=\"constrained\")\n",
    "for ax in axs:\n",
    "    ax.grid()\n",
    "\n",
    "axs[0].set_ylim([0.0,2.0])\n",
    "axs[0].set_xlabel(r\"Epoch\", fontsize=12)\n",
    "axs[0].set_ylabel(r\"$\\mathcal{L}oss$\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    xs = torch.linspace(0.0, len(train_losses), len(train_losses))\n",
    "    axs[0].plot(xs, train_losses, label=\"Training loss\")\n",
    "    axs[0].plot(xs, val_losses, label=\"Validation loss\")\n",
    "    axs[0].plot([], [], label=f\"Final test loss: {round(test_loss.item(),3)}\", c=\"r\")\n",
    "    for ax, loader, color, label in zip([axs[1], axs[2]], [train_loader, val_loader], [\"C0\", \"C1\"], [\"Training data\", \"Validation data\"]):\n",
    "        ax.set_xlim([-45,-15])\n",
    "        ax.set_ylim([-45,-15])\n",
    "        ax.set_xlabel(r\"$E_{real}$\", fontsize=12)\n",
    "        ax.set_ylabel(r\"$E_{LJG}-model$\", fontsize=12)\n",
    "        i = 0\n",
    "        for coords, energies in loader:\n",
    "            e_model = LJGmodel.forward(coords)\n",
    "            if i == 0:\n",
    "                ax.plot(e_model, energies, 'o', color=color, alpha=0.5, label=label)\n",
    "            else:\n",
    "                ax.plot(e_model, energies, 'o', color=color, alpha=0.5)\n",
    "            i+=1\n",
    "        xs = np.linspace(-42, -17, 100)\n",
    "        ax.plot(xs, xs, c=\"k\", lw=1, ls=\"--\")\n",
    "        ax.legend()\n",
    "    rs = torch.linspace(0.2, 4.0, 1000)\n",
    "    axs[3].set_xlabel(r\"$r$\", fontsize=12)\n",
    "    axs[3].set_ylabel(r\"$V(r)$\", fontsize=12)\n",
    "    axs[3].set_ylim([-1.5,2.0])\n",
    "    axs[3].set_xlim([0.0,3.0])\n",
    "    axs[3].plot(rs, LJGmodel._V(rs), label=r\"$V(r)$\")\n",
    "    axs[3].legend()\n",
    "    axs[0].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pot_NN(torch.nn.Module):\n",
    "    def __init__(self, num_hidden_layers=4, dim_hiddens=15, activation_func=torch.nn.Softplus(), bias=True) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_layers = torch.nn.ParameterList()\n",
    "        self.input_layer = torch.nn.Linear(1, dim_hiddens, bias=bias, dtype=torch.float)\n",
    "        self.output_layer = torch.nn.Linear(dim_hiddens, 1, bias=bias, dtype=torch.float)\n",
    "        self.activation_func = activation_func\n",
    "        for num in range(num_hidden_layers):\n",
    "            self.hidden_layers.append(torch.nn.Linear(dim_hiddens, dim_hiddens, bias=bias, dtype=torch.float))\n",
    "\n",
    "    def _V(self, r):\n",
    "        pot = self.activation_func(self.input_layer(r))\n",
    "        for layer in self.hidden_layers:\n",
    "            pot = self.activation_func(layer(pot))\n",
    "        return self.output_layer(pot)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        pairwise_distances = torch.stack([torch.pdist(coords[i]) for i in range(coords.size(0))]).unsqueeze(-1)\n",
    "        #print(torch.sum(self._V(pairwise_distances), dim=1).view(-1))\n",
    "        return torch.sum(self._V(pairwise_distances), dim=1).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "patience=100\n",
    "NNmodel = Pot_NN()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=NNmodel.parameters(), lr=1e-3)\n",
    "train_losses, val_losses, test_loss = train_model(epochs=epochs, model=NNmodel, \n",
    "                                       train_loader=train_loader, \n",
    "                                       val_loader=val_loader, \n",
    "                                       optimizer=optimizer, \n",
    "                                       test_loader=test_loader, \n",
    "                                       early_stopping=True,\n",
    "                                       patience=patience\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,4, figsize=(14,3), layout=\"constrained\")\n",
    "for ax in axs:\n",
    "    ax.grid()\n",
    "\n",
    "axs[0].set_ylim([0.0,2.0])\n",
    "axs[0].set_xlabel(r\"Epoch\", fontsize=12)\n",
    "axs[0].set_ylabel(r\"$\\mathcal{L}oss$\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    xs = torch.linspace(0.0, len(train_losses), len(train_losses))\n",
    "    axs[0].plot(xs, train_losses, label=\"Training loss\")\n",
    "    axs[0].plot(xs, val_losses, label=\"Validation loss\")\n",
    "    axs[0].plot([], [], label=f\"Final test loss: {round(test_loss.item(),3)}\", c=\"r\")\n",
    "    for ax, loader, color, label in zip([axs[1], axs[2]], [train_loader, val_loader], [\"C0\", \"C1\"], [\"Training data\", \"Validation data\"]):\n",
    "        ax.set_xlim([-45,-15])\n",
    "        ax.set_ylim([-45,-15])\n",
    "        ax.set_xlabel(r\"$E_{real}$\", fontsize=12)\n",
    "        ax.set_ylabel(r\"$E_{NN}-model$\", fontsize=12)\n",
    "        i = 0\n",
    "        for coords, energies in loader:\n",
    "            e_model = NNmodel.forward(coords)\n",
    "            if i == 0:\n",
    "                ax.plot(e_model, energies, 'o', color=color, alpha=0.5, label=label)\n",
    "            else:\n",
    "                ax.plot(e_model, energies, 'o', color=color, alpha=0.5)\n",
    "            i+=1\n",
    "        xs = np.linspace(-42, -17, 100)\n",
    "        ax.plot(xs, xs, c=\"k\", lw=1, ls=\"--\")\n",
    "        ax.legend()\n",
    "    rs = torch.linspace(0.2, 4.0, 1000).view(-1,1)\n",
    "    axs[3].set_xlabel(r\"$r$\", fontsize=12)\n",
    "    axs[3].set_ylabel(r\"$V(r)$\", fontsize=12)\n",
    "    axs[3].set_ylim([-1.5,2.0])\n",
    "    axs[3].set_xlim([0.0,3.0])\n",
    "    axs[3].plot(rs, NNmodel._V(rs), label=r\"$NN-fit$\", lw=2)\n",
    "    axs[3].plot(rs, LJGmodel._V(rs), label=r\"$LJG-fit$\", ls=\"--\", c=\"k\", lw=1)\n",
    "    axs[3].legend()\n",
    "    axs[0].legend()\n",
    "plt.savefig(\"Label1.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 8000\n",
    "patience= 1000\n",
    "models = [Pot_NN(num_hidden_layers=4, dim_hiddens=16), Pot_NN(num_hidden_layers=4, dim_hiddens=16), LJGNN()]\n",
    "\n",
    "ENERGY_LABEL = 2\n",
    "\n",
    "dataset_train = ClusterDataset(data_in_file[0:799], label_index=ENERGY_LABEL)\n",
    "dataset_val = ClusterDataset(data_in_file[799:899], label_index=ENERGY_LABEL)\n",
    "dataset_test = ClusterDataset(data_in_file[899:999], label_index=ENERGY_LABEL)\n",
    "train_loader = DataLoader(dataset=dataset_train, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset=dataset_val, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=dataset_test, batch_size=32, shuffle=True)\n",
    "model_losses = []\n",
    "for model in models:\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)\n",
    "    train_losses, val_losses, test_loss = train_model(epochs=epochs, model=model, \n",
    "                                                      train_loader=train_loader, \n",
    "                                                      val_loader=val_loader, \n",
    "                                                      optimizer=optimizer,\n",
    "                                                      test_loader=test_loader, \n",
    "                                                      early_stopping=True,\n",
    "                                                      patience=patience)\n",
    "    model_losses.append([train_losses, val_losses, test_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axss = plt.subplots(2,4, figsize=(17,9))\n",
    "for ax in axss.flatten():\n",
    "    ax.grid()\n",
    "\n",
    "for model, axs, model_loss in zip(models, [axss[0], axss[1]], model_losses):\n",
    "    axs[0].set_ylim([0.0,2.0])\n",
    "    with torch.no_grad():\n",
    "        xs = torch.linspace(0.0, len(model_loss[0]), len(model_loss[0]))\n",
    "        axs[0].plot(xs, model_loss[0], label=\"Training loss\")\n",
    "        axs[0].plot(xs, model_loss[1], label=\"Validation loss\")\n",
    "        axs[0].legend()\n",
    "        for ax, loader, color in zip([axs[1], axs[2]], [train_loader, val_loader], [\"C0\", \"C1\"]):\n",
    "            ax.set_xlim([-45,-15])\n",
    "            ax.set_ylim([-45,-15])\n",
    "            for coords, energies in loader:\n",
    "                e_model = model.forward(coords)\n",
    "                ax.plot(e_model, energies, 'o', color=color, alpha=0.5)\n",
    "        rs = torch.linspace(0.2, 4.0, 1000)\n",
    "        axs[3].set_ylim([-1.5,2.0])\n",
    "        axs[3].set_xlim([0.0,3.0])\n",
    "        axs[3].plot(rs, model._V(rs.view(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
