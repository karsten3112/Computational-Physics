{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, \"../../\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from classes.nn_classes import train_model, NNmodel\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterDataset(Dataset):\n",
    "    def __init__(self, data_from_file, label_index=1) -> None:\n",
    "        super().__init__()\n",
    "        self.data = torch.tensor(np.array([data[0] for data in data_from_file]),dtype=torch.float32)\n",
    "        self.labels = torch.tensor(np.array([data[label_index] for data in data_from_file]),dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flat = np.loadtxt('../pos_e1_e2_e3_1000.txt')\n",
    "data_in_file = [[d[:24].reshape(12,2),d[24],d[25],d[26]] for d in data_flat]\n",
    "\n",
    "ENERGY_LABEL = 2\n",
    "\n",
    "dataset_train = ClusterDataset(data_in_file[0:799], label_index=ENERGY_LABEL)\n",
    "dataset_val = ClusterDataset(data_in_file[799:899], label_index=ENERGY_LABEL)\n",
    "dataset_test = ClusterDataset(data_in_file[899:999], label_index=ENERGY_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LJGNN(torch.nn.Module):\n",
    "    def __init__(self, eps=0.5, sigma_squared=0.03, r0=1.6, eInf=0.1, A=0.9) -> None:\n",
    "        super().__init__()\n",
    "        self.A = torch.nn.Parameter(torch.tensor(float(A)))\n",
    "        self.eps = torch.nn.Parameter(torch.tensor(float(eps)))\n",
    "        self.r0 = torch.nn.Parameter(torch.tensor(float(r0)))\n",
    "        self.sigma_squared = torch.nn.Parameter(torch.tensor(float(sigma_squared)))\n",
    "        self.epsinf = torch.nn.Parameter(torch.tensor(float(eInf)))\n",
    "    \n",
    "    def _V(self, r):\n",
    "        t1 = self.eps*torch.exp(-(r - self.r0)**2/(2.0*self.sigma_squared))\n",
    "        t2 = (1.0/r)**12 - 2.0*(1.0/r)**6\n",
    "        return self.A*(t2-t1) + self.epsinf\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        pairwise_distances = torch.stack([torch.pdist(coords[i]) for i in range(coords.size(0))])\n",
    "        return torch.sum(self._V(pairwise_distances), dim=1)\n",
    "\n",
    "class Pot_NN(torch.nn.Module):\n",
    "    def __init__(self, num_hidden_layers=4, dim_hiddens=15, activation_func=torch.nn.Softplus(), bias=True) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden_layers = torch.nn.ParameterList()\n",
    "        self.input_layer = torch.nn.Linear(1, dim_hiddens, bias=bias, dtype=torch.float)\n",
    "        self.output_layer = torch.nn.Linear(dim_hiddens, 1, bias=bias, dtype=torch.float)\n",
    "        self.activation_func = activation_func\n",
    "        for num in range(num_hidden_layers):\n",
    "            self.hidden_layers.append(torch.nn.Linear(dim_hiddens, dim_hiddens, bias=bias, dtype=torch.float))\n",
    "\n",
    "    def _V(self, r):\n",
    "        pot = self.activation_func(self.input_layer(r))\n",
    "        for layer in self.hidden_layers:\n",
    "            pot = self.activation_func(layer(pot))\n",
    "        return self.output_layer(pot)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        pairwise_distances = torch.stack([torch.pdist(coords[i]) for i in range(coords.size(0))])\n",
    "        return torch.sum(self._V(pairwise_distances), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=dataset_train, batch_size=10, shuffle=True)\n",
    "val_loader = DataLoader(dataset=dataset_val, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(dataset=dataset_test, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 8000\n",
    "patience= 1000\n",
    "models = [Pot_NN(num_hidden_layers=4, dim_hiddens=16), Pot_NN(num_hidden_layers=4, dim_hiddens=16), LJGNN()]\n",
    "\n",
    "model_losses = []\n",
    "for model in models:\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)\n",
    "    train_losses, val_losses, test_loss = train_model(epochs=epochs, model=model, \n",
    "                                                      train_loader=train_loader, \n",
    "                                                      val_loader=val_loader, \n",
    "                                                      optimizer=optimizer,\n",
    "                                                      test_loader=test_loader, \n",
    "                                                      early_stopping=True,\n",
    "                                                      patience=patience)\n",
    "    model_losses.append([train_losses, val_losses, test_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
